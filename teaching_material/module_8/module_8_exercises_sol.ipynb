{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-23T15:30:03.634114Z",
     "start_time": "2017-08-23T15:30:03.629294Z"
    }
   },
   "source": [
    "# Exercises for Session 8: Advanced Web Scraping and Regex\n",
    "\n",
    "In this Exercise Set we shall develop our web scraping skills even further by practicing using `Selenium` while parsing and navigating HTML trees using `BeautifulSoup`. Furthermore we will train extracting information from raw text with no HTML tags to help using `Regex`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Translating domains into companies\n",
    "This exercise is about solving a problem that some of you may face in the future. All webshops (and most other websites) have a company as their owner. In some situations it might be useful to know which company owns the domain of the webshop and investigate the background of the company.\n",
    "\n",
    "It is what we will do in this exercise. We will use www.netbaby.dk as an example, but the procedure can be scaled to 1000s of websites. This is where automated browsing and web scraping shines! With just one website we can easily find the information by hand, but with 1000s of websites we need automated web scraping.\n",
    "\n",
    "Remember to watch the video (8.1) below before moving on to the exercises:\n",
    "\n",
    "(I might talk a bit slow in some of the videos. Remember that you can turn up the speed on Youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('reO8F8orK3I', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.1:** Use `Selenium` to go to the website https://www.dk-hostmaster.dk/da/find-domaenenavn and search for \"netbaby.dk\". \n",
    "\n",
    "> Under \"Registrant\" you can see the name (\"Navn\") of the company behind netbaby.dk. Use `BeautifulSoup` to find the name of the company and store it in the variable `company`.\n",
    "> - I.e., you need to use the skills you developed in session 7 to locate the name of the company in the HTML and extract the name from the HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 104.0.5112\n",
      "[WDM] - Get LATEST chromedriver version for 104.0.5112 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\mqt509\\.wdm\\drivers\\chromedriver\\win32\\104.0.5112.79\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "url = 'https://www.dk-hostmaster.dk/da/find-domaenenavn'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(100) #Waits maximum 100 seconds for an element to be found in the HTML.\n",
    "driver.get(url)\n",
    "\n",
    "# We need to click away the popup box with cookie information\n",
    "cookie = driver.find_element(By.ID, 'CybotCookiebotDialogBodyLevelButtonLevelOptinAllowallSelection')\n",
    "cookie.click()\n",
    "\n",
    "# Find the place to type in search text\n",
    "inputElement = driver.find_element(By.ID, 'query_domain')\n",
    "inputElement.click() #And click\n",
    "# Type the search text\n",
    "inputElement.send_keys('netbaby.dk')\n",
    "# Use \"Return\" key to search\n",
    "inputElement.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euphemia Media\n"
     ]
    }
   ],
   "source": [
    "# Find the name of the company\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "html = driver.page_source #Selenium stores the HTML of the webpage in .page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# The id attribute of the registrant name is 'domain_registrant_name'\n",
    "company = soup.find(id='domain_registrant_name')\n",
    "company = company.text\n",
    "\n",
    "print(company)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.1.2:** Now we know who owns the domain and would like to know more about the company Euphemia Media. \n",
    "\n",
    "> 1. Go to the Central Business Register (the CVR) website https://datacvr.virk.dk/data/. Search for Euphemia Media using `Selenium`. \n",
    "> 2. You will find 2 search results. Use `Selenium` to click on the first result.\n",
    "> 3. When you get to the first search result, use `BeautifulSoup` to store the CVR number in the variable *cvr*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 104.0.5112\n",
      "[WDM] - Get LATEST chromedriver version for 104.0.5112 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\mqt509\\.wdm\\drivers\\chromedriver\\win32\\104.0.5112.79\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "url = 'https://datacvr.virk.dk/data/'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.implicitly_wait(100) #Waits maximum 100 seconds for an element to be found in the HTML.\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# We need to click away the popup box with cookie information\n",
    "cookie = driver.find_element(By.CSS_SELECTOR, 'a.cpAcceptBtn') #Here we use a CSS selector\n",
    "cookie.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the place to type in search text\n",
    "inputElement = driver.find_element(By.ID, 'forside-soegefelt-id')\n",
    "inputElement.click()\n",
    "# Type the search text\n",
    "inputElement.send_keys(company)\n",
    "# Use \"Return\" key to search\n",
    "inputElement.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the place to click on the first search result\n",
    "search_result = driver.find_elements(By.CSS_SELECTOR, 'span.bold.value') #Here we use a CSS selector\n",
    "search_result = search_result[0] #There are two elements matching this CSS selector (the two search results). We take the first one.\n",
    "search_result.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the CVR number\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# There is no unique class or id attribute that identifies the CVR number.\n",
    "# So I use a CSS selector \n",
    "cvr = soup.select('div.col-6.col-lg-9')\n",
    "# The CSS selector also finds more elements. I notice that the first element is the CVR number. I select that.\n",
    "cvr = cvr[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21848875'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvr\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "The Central Business Register actually also have an API: https://datacvr.virk.dk/artikel/system-til-system-adgang-til-cvr-data.\n",
    "\n",
    "Whenever there is an API available, you should use it. It is way more reliable than trying to web scrape the webpage by yourself.\n",
    "\n",
    "We just did it in this exercise for educational purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Practicing Regular Expressions\n",
    "\n",
    "In this exercise you will gain experience in working with regular expressions. Regular expressions takes time to get used to, so do not panic if you do not understand the intuition at first. The only way to get familiar with their structure and applicability is to work with them. \n",
    "\n",
    "And they ARE very useful! I promise you that if you at some point are going to work with text as data, then you will find RegEx solutions to your problems. They are all over StackOverflow. We will only scratch the surface, but you will soon become better when you apply RegEx to your own text analysis problems.\n",
    "\n",
    "Note: A good webpage to have in mind is this one: www.regular-expressions.info/refquick.html. It contains all special symbols that RegEx uses.\n",
    "\n",
    "Before moving to the exercises below, remember to watch the following video (8.2):\n",
    "\n",
    "(I might talk a bit slow in some of the videos. Remember that you can turn up the speed on Youtube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo('5vCE_7KSO7Y', width=640, height=360)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice RegEx we will use a review from a dataset with Trustpilot reviews collected by a colleague Snorre Ralund.\n",
    "You can load it directly into python using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Download data\n",
    "path2data = 'https://raw.githubusercontent.com/snorreralund/scraping_seminar/master/english_review_sample.csv'\n",
    "df = pd.read_csv(path2data)\n",
    "\n",
    "# Take the review we are going to play with\n",
    "review = df.reviewBody[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I've been to the 'other' sac store in the Mall of America many times and my wife and I always leave the store wanting a big comfy sac to lounge in... but the cost just doesn't add up.  I don't mind paying for good products, but there is a point where things are just too expensive.\\r\\n\\r\\nI did my research online, found Comfy Sacks and after much contemplation I decided if Comfy Sacks are good enough for Amazon/Apple Corp, then they'd be good enough for me.\\r\\n\\r\\nI chose the 6ft sack with a brown textured premium suede.  Wow, is all I can say!!  Quality is amazing, comfort is great and it fits my whole family (Wife, 5yo daughter and me).\\r\\n\\r\\n*You do have to 'fluff' it every now and then and it's shipped in such a tight vacuum packed 'block' it does take a fair amount of effort to de-compress it the first time.  Check Youtube for other reviews, it was very helpful for me.\\r\\n\\r\\nOverall, I'd recommend this to anyone looking at the $900+ alternatives.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.1:** First, we are interested in the *first* number in the review. Make a regular expression that matches the first number in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "import re\n",
    "first_number = re.search(r'\\d+', review) \n",
    "first_number.group()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.2:** Now, we are interested in *all* the numbers in the review. Make a regular expression that matches all numbers in the text.\n",
    "\n",
    "> Afterwards make a new regex that only matches numbers with a non-alphanumeric character (\\$, +, etc.) before and after the number. Include the non-alphanumeric characters in the match (for example \\\\$900+)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6', '5', '900']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "# Find numbers\n",
    "numbers = re.findall(r'\\d+', review) \n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$900+']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find number with special characters pre- and proceding\n",
    "number_chr = re.findall(r'\\W\\d+\\W', review) \n",
    "number_chr\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.3:** Let's say we want the text inside the parenthesis in the review. Write a regex that matches that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Wife, 5yo daughter and me)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "par_text = re.findall(r'\\(.+\\)', review) #Remember that the parenthesis \"(\" is also a special character in regex, so we have to escape it with \"\\\".\n",
    "par_text\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Ex. 8.2.4:** The review consists of different lines with line breaks. Split the text into each line and store them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I've been to the 'other' sac store in the Mall of America many times and my wife and I always leave the store wanting a big comfy sac to lounge in... but the cost just doesn't add up.  I don't mind paying for good products, but there is a point where things are just too expensive.\",\n",
       " \"I did my research online, found Comfy Sacks and after much contemplation I decided if Comfy Sacks are good enough for Amazon/Apple Corp, then they'd be good enough for me.\",\n",
       " 'I chose the 6ft sack with a brown textured premium suede.  Wow, is all I can say!!  Quality is amazing, comfort is great and it fits my whole family (Wife, 5yo daughter and me).',\n",
       " \"*You do have to 'fluff' it every now and then and it's shipped in such a tight vacuum packed 'block' it does take a fair amount of effort to de-compress it the first time.  Check Youtube for other reviews, it was very helpful for me.\",\n",
       " \"Overall, I'd recommend this to anyone looking at the $900+ alternatives.\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "lines = re.split(r\"\\r\\n\\r\\n\", review)\n",
    "lines\n",
    "### END SOLUTION"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "328px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
