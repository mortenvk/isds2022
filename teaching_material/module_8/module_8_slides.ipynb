{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Session 8: Advanced webscraping; Automated Browsing and Regular Expressions\n",
    "\n",
    "*Hjalte Fejerskov Boas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap\n",
    "\n",
    "In sessions 6 and 7 we learned how to:\n",
    "\n",
    "1. map our URLs of interest\n",
    "2. download the HTML of the webpages\n",
    "3. parse the data from the HTML\n",
    "    - HTML is the language behind webpages\n",
    "    - We can use `BeautifulSoup` to find the right places in the HTML (where is the data of interest hidden in the HTML?)\n",
    "    - We learned how to structure our acquired data in dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our focus was on the HTML and how to extract information from it! \n",
    "- Sometimes just downloading the HTML is not enough to extract the data you need\n",
    "\n",
    "We might need to interact with the webpage to bring forward the information in the HTML\n",
    "- Here automated browsing is our friend, and that is the focus of session 8!\n",
    "\n",
    "In this session, you will also learn about regular expressions that you can use to process raw text (i.e. not HTML text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Required readings\n",
    "\n",
    "- Introduction to Web Scraping using Selenium: [An introduction to Selenium in Python](https://medium.com/the-andela-way/introduction-to-web-scraping-using-selenium-7ec377a8cf72)\n",
    "\n",
    "- Introduction to pattern matching using regex: [An introduction to regex in python](https://www.digitalocean.com/community/tutorials/an-introduction-to-regex-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview of Session 8\n",
    "Today we will learn about automated browsing and regular expressions.\n",
    "\n",
    "1. Automated browsing\n",
    "    - Why is it useful?\n",
    "    - Learning by doing: We will browse through www.nboard.dk\n",
    "        - You will learn about scrolling, clicking, sending keys and combining `Selenium` and `BeautifulSoup`\n",
    "2. Regular Expressions\n",
    "    - What is it?\n",
    "    - Where can you learn more?\n",
    "    - Build simple regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Interactions and Automated Browsing\n",
    "\n",
    "Automated browsing means letting the computer do the things you normally do:\n",
    "- Log in\n",
    "- Type in search text\n",
    "- Scroll down page\n",
    "- Click on links\n",
    "\n",
    "Sometimes webscraping demands such interactions with the webpage to extract the information you want\n",
    "\n",
    "To make the interactions we use the Python package [`Selenium`](https://selenium-python.readthedocs.io/). In combination with the virtual browser [`ChromeDriver`](https://chromedriver.chromium.org/) we can completely automate our browsing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note: If you have not installed `Selenium` yet, \"pip install selenium\" should do the trick."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Let 's see how it works:\n",
    "\n",
    "- In the code below we first open our virtual browser \n",
    "- From the virtual browser we can execute `Selenium` commands (for example go to google.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "[WDM] - About to download new driver from https://chromedriver.storage.googleapis.com/103.0.5060.134/chromedriver_win32.zip\n",
      "[WDM] - Driver has been saved in cache [C:\\Users\\mqt509\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# We open up google.com in a virtual browser\n",
    "url = 'https:google.com'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install()) #Open virtual browser\n",
    "driver.get(url) #Go to google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Benefits from automated browsing\n",
    "1. You can access data that are not directly in the HTML but that is being generated while browsing\n",
    "2. You can get through login screens and other scraping barriers\n",
    "3. You can automate browsing behaviour such as scrolling down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Video 8.1: Automated browsing with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Learning by doing: Automated browsing of www.nboard.dk\n",
    "\n",
    "www.nboard.dk is a website that connects companies with potential board members. \n",
    "\n",
    "In this exercise we want to browse the site for potential board members. We will do this automatically with `Selenium`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 1: \n",
    "Load the webpage we want to scrape in our virtual browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 103.0.5060\n",
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n",
      "[WDM] - Driver [C:\\Users\\mqt509\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.134\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "url = 'https://nboard.dk/search'\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 2: \n",
    "We want to click away the \"cookie notification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "cookie = driver.find_element(By.CSS_SELECTOR, '.cc-dismiss') #Here we use a CSS selector\n",
    "cookie.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 3: \n",
    "We only want the board members (\"Bestyrelsesmedlem\")\n",
    "- We need to click the box \"Bestyrelsesmedlem\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "boardmember = driver.find_element_by_id('mat-checkbox-2') #Here we use the id attribute to find the chairman box\n",
    "boardmember.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 4: \n",
    "Now we scroll down the page to load more profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for i in range(5): #We scroll down 5 times and sleep for 3 seconds each time to wait for the webpage to load\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #Execute JavaScript on the browser that scroll down page\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 5: \n",
    "We decide that we only want profiles with the surname \"Hansen\". So we need to go to \"Søg på kandidatnavn\" and type in Hansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Find the place to type in search text\n",
    "candidate = driver.find_element_by_id('mat-input-4')\n",
    "candidate.click() #And click\n",
    "# Type the search text\n",
    "candidate.send_keys('Hansen') #Use the `.send_keys` to type text. `.send_keys` imitates your computer keyboard, so you can for example also press the 'Return' or 'PgDn' botton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 6: \n",
    "Now we want to know how many profiles satisfy our criteria. So first we need to save the HTML with `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, 'lxml') #The Selenium Driver keeps the HTML in the `.page_source` property\n",
    "\n",
    "# Find the place where the number of profiles is shown\n",
    "results = soup.find_all('span', class_ = \"ng-tns-c10-0\")\n",
    "results = results[4] #More elements matches the search, so we take the number of profiles element only\n",
    "\n",
    "# We only want the text content of the HTML\n",
    "profiles = results.text #We take the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Antal resultater: 105 | Sortering: Mest relevante først.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Step 7: \n",
    "We only want the number of profiles, but there are still some other text as well\n",
    "\n",
    "We cannot get any further with `BeautifulSoup`, so we use `Regex` to take out the number from the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We are only interested in the number, so we take out the number from the string using RegEx\n",
    "import re\n",
    "number_profiles = re.search(r'\\d+', profiles) #The '\\d' searches for digits in the string, and the '+' tells regex to search for all digits. The 'r' in the front of the string makes the string into a raw string; it means that for example \\n (new line) is not interpreted as new line, but is just seen as '\\n'.\n",
    "number_profiles = number_profiles.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'105'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Next level scrapers\n",
    "\n",
    "You have now learned the fundamentals of collecting and parsing data from the web. \n",
    "\n",
    "#### One last note about challenges of scraping: \n",
    "Many online companies have made a business out of data\n",
    "- They do not necessarily want to share all their data with you \n",
    "- Facebook, LinkedIn, Google and all the other big tech firms are battling scrapers by creating all kinds of obstacles to make it hard for us to scrape their data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I have found some articles that address these obstacles. You might find them interesting.\n",
    "\n",
    "- [Most Commonly used techniques to Prevent Scraping:](https://medium.com/@betoayesa/using-the-content-as-an-anti-scrape-weapon-draft-9bb10cd30e5c)\n",
    "- [Advanced Web Scraping Tactics](https://www.pluralsight.com/guides/advanced-web-scraping-tactics-python-playbook)\n",
    "- [Scraping Sites That Use JavaScript and AJAX](https://oup-arc.com/protected/files/content/file/1505319833942-CH9---Scraping-Sites-that-Use-JavaScript-and-AJAX.pdf)\n",
    "- [Get Started Scraping LinkedIn With Python and Selenium](https://medium.com/nerd-for-tech/linked-in-web-scraper-using-selenium-15189959b3ba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Remember\n",
    "You know the fundamentals about web scraping\n",
    "- But a web scraping course will never be able to prepare you for all situations\n",
    "- The only way to get better is to go work on your own web scraping problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Video 8.2: Extracting patterns from text using RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Regex\n",
    "A regular expression (shortened as regex) is a sequence of characters that defines a search pattern\n",
    "\n",
    "The patterns are used by string-searching algorithms for \"find\"- or \"find and replace\"- operations on strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Examples\n",
    "- Extract currency and amount from raw text: $ 20, 10.000 dollars 10,000 £\n",
    "- Email addresses: Design a pattern, that captures only the uses of @ within an email.\n",
    "- URLs: Define all the different ways of writing URLs (https, http, no http). \n",
    "- Dates: There are many variations: 17th of June 2017, 06/17/17 or 17. June 17\n",
    "- Addresses \n",
    "- Phone numbers: 8888888 or 88 88 88 88 or +45 88 88 88 88\n",
    "- Emojiies in text: Capturing all the different ways of expressing smiley faces with one regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Note:\n",
    "- We will only scratch the surface of regex!\n",
    "\n",
    "- It takes time to understand the intuition behind regex\n",
    "\n",
    "- The only way to become better is by using it in practice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Ressources\n",
    "- Use this interactive regex tester to test your regex: http://regexr.com/\n",
    "- Interactive tutorial: https://regexone.com/\n",
    "- Lookup all special characters: https://www.regular-expressions.info/refquick.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Some important syntax for build your own expresions\n",
    "### See more in this [tutorial](https://www.digitalocean.com/community/tutorials/an-introduction-to-regex-in-python) and this [guide](https://www.regular-expressions.info/refquick.html)\n",
    "* \\+ = 1 or more times  -- e.g. \"a+\" will match: \"a\", and \"aaa\"\n",
    "* \\* = 0 or more times  -- e.g. \"ba*\" will match: \"b\", and \"ba\", and \"baaa\"\n",
    "* {3} = exactly three times --- e.g. \"ba{3}\" will match \"baaa\", but not \"baa\"\n",
    "* ? = once or none\n",
    "* \\\\ = escape character, used to find characters that has special meaning with regex: e.g. \\+ \\*\n",
    "* [] = allows you to define a set of characters\n",
    "* () = groups a part of the regular expression\n",
    "* ^ = applied within a set, it becomes the inverse of the set defined. Applied outside a set it entails the beginning of a string. $ entails the end of a string.\n",
    "* . = any characters except line break\n",
    "* | = or statement. -- e.g. a|b means find characters a or b.\n",
    "* \\d = digits\n",
    "* \\D = non-digits.\n",
    "* \\s = whitespace-separator\n",
    "* \\w = matches alphanumeric character [a-zA-Z0-9_]\n",
    "* \\W = matches any non-alphanumeric character [^a-zA-Z0-9]\n",
    "\n",
    "Sequences\n",
    "* (?:) = Defines a Non-capturing group. -- e.g. \"(?:abc)+\", will match \"abc\" and \"abcabcabc\", but not \"aabbcc\"\n",
    "* (?=)\t= Positive lookahead - only match a certain pattern if a certain pattern comes after it.\n",
    "* (?!)\t= Negative lookahead - only match a certain pattern if **not** a certain pattern comes after it.\n",
    "* (?<=)\t= Positive lookbehind - only match a certain pattern if a certain pattern precedes it.\n",
    "* (?<!) = Negative lookbehind - only match a certain pattern if **not** a certain pattern precedes it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regular expressions in action\n",
    "\n",
    "### In the code pieces below, you will see some common uses of regular expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### First we need some text to practice on\n",
    "We will use a piece of one of the articles we downloaded from www.dr.dk in session 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Gazprom halverer gasleverancerne til Europa via Nord Stream 1. Årsagen er ifølge selskabet vedligehold af en gasturbine. Den daglige gasforsyning via gasledningen vil fra onsdag morgen blive reduceret til 33 millioner kubikmeter, oplyser Gazprom.Det svarer til cirka 20 procent af den maksimale kapacitet, og det fremgår ikke, hvor længe den yderligt reducerede forsyning af gas vil stå på.Den tyske regering anser den forklaringen om vedligeholdelse for at være opfundet til lejligheden.- Ifølge vores oplysninger er der ingen teknisk grund til en reduktion i leverancerne, siger en talskvinde for Finansministeriet og minister Robert Habeck til Frankfurter Allgemeine Zeitung.Tyskerne får 25 procent af deres energi fra gas, hvor en overvejende del er kommet fra Rusland.Gasprisen stiger med 10 procentDet er anden gang indenfor en uge, at Gazprom reducerer leverancen af gas under påskud af reperation af gasturbiner. Da Gazprom efter ti dages vedligehold i sidste uge genåbnede for gasforsyningen til Tyskland, var meldingen, at der dagligt ville blive leveret cirka 67 millioner kubikmeter.Gazproms seneste melding betyder altså, at leverancerne til Europa bliver omtrent halveret fra onsdag. Gasledningen kan, når den kører for fuld kraft, levere cirka 167 millioner kubikmeter gas om dagen.Nordstream 1-faciliter i Lubmin i Tyskland. (Foto:\\xa0HANNIBAL HANSCHKE ©\\xa0Ritzau Scanpix)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gazprom halverer gasleverancerne til Europa via Nord Stream 1. Årsagen er ifølge selskabet vedligehold af en gasturbine. Den daglige gasforsyning via gasledningen vil fra onsdag morgen blive reduceret til 33 millioner kubikmeter, oplyser Gazprom.Det svarer til cirka 20 procent af den maksimale kapacitet, og det fremgår ikke, hvor længe den yderligt reducerede forsyning af gas vil stå på.Den tyske regering anser den forklaringen om vedligeholdelse for at være opfundet til lejligheden.- Ifølge vores oplysninger er der ingen teknisk grund til en reduktion i leverancerne, siger en talskvinde for Finansministeriet og minister Robert Habeck til Frankfurter Allgemeine Zeitung.Tyskerne får 25 procent af deres energi fra gas, hvor en overvejende del er kommet fra Rusland.Gasprisen stiger med 10 procentDet er anden gang indenfor en uge, at Gazprom reducerer leverancen af gas under påskud af reperation af gasturbiner. Da Gazprom efter ti dages vedligehold i sidste uge genåbnede for gasforsyningen til Tyskland, var meldingen, at der dagligt ville blive leveret cirka 67 millioner kubikmeter.Gazproms seneste melding betyder altså, at leverancerne til Europa bliver omtrent halveret fra onsdag. Gasledningen kan, når den kører for fuld kraft, levere cirka 167 millioner kubikmeter gas om dagen.Nordstream 1-faciliter i Lubmin i Tyskland. (Foto:\\xa0HANNIBAL HANSCHKE ©\\xa0Ritzau Scanpix)'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 1. Find the first digit in a text\n",
    "Use the [`search()`](https://www.pythontutorial.net/python-regex/python-regex-search/) function\n",
    "\n",
    "- `\\d` finds any digit in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "first_digit = re.search(r'\\d+', text) \n",
    "first_digit.group() #group() returns the matched string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 2. Find all digits in a text\n",
    "Use the [`findall()`](https://www.pythontutorial.net/python-regex/python-regex-findall/) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '33', '20', '25', '10', '67', '167', '1']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_digits = re.findall(r'\\d+', text) \n",
    "all_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 3. Find all digits with 'millioner' after \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33 millioner', '67 millioner', '167 millioner']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "millioner = re.findall(r'\\d+ millioner', text) \n",
    "millioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 4. We are now interested in the quotes in the text\n",
    "We need to search for the text with the pattern: \n",
    "- First a '-'\n",
    "- Then the text\n",
    "- Ended by a ','\n",
    "\n",
    "`\\w` finds any alphanumeric characters \\[a-zA-Z0-9_\\]. Oppositely, `\\W` finds any non-alphanumeric character \\[^a-zA-Z0-9\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- Ifølge vores oplysninger er der ingen teknisk grund til en reduktion i leverancerne,']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote = re.findall(r'- [\\w ]+,', text) \n",
    "quote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 5. What if we want the information about the photo \n",
    "We want the information about the photo inside parentheses\n",
    "- Remember that \"(\" and \")\" are special characters in regex, so we have to escape its special function with \"\\\"\n",
    "- \".\" matches any character except \"\\n\" (new line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(Foto:\\xa0HANNIBAL HANSCHKE ©\\xa0Ritzau Scanpix)']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photo = re.findall(r'\\(.+\\)', text)\n",
    "photo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 6. The text consists of different sentences. We want to break the text down to each sentence\n",
    "\n",
    "The [`split()`](https://www.pythontutorial.net/python-regex/python-regex-split/) function can split a string at the occurrences of matches of a regular expression\n",
    "\n",
    "Each sentence ends with a \".\". Let us split on that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gazprom halverer gasleverancerne til Europa via Nord Stream 1',\n",
       " ' Årsagen er ifølge selskabet vedligehold af en gasturbine',\n",
       " ' Den daglige gasforsyning via gasledningen vil fra onsdag morgen blive reduceret til 33 millioner kubikmeter, oplyser Gazprom',\n",
       " 'Det svarer til cirka 20 procent af den maksimale kapacitet, og det fremgår ikke, hvor længe den yderligt reducerede forsyning af gas vil stå på',\n",
       " 'Den tyske regering anser den forklaringen om vedligeholdelse for at være opfundet til lejligheden',\n",
       " '- Ifølge vores oplysninger er der ingen teknisk grund til en reduktion i leverancerne, siger en talskvinde for Finansministeriet og minister Robert Habeck til Frankfurter Allgemeine Zeitung',\n",
       " 'Tyskerne får 25 procent af deres energi fra gas, hvor en overvejende del er kommet fra Rusland',\n",
       " 'Gasprisen stiger med 10 procentDet er anden gang indenfor en uge, at Gazprom reducerer leverancen af gas under påskud af reperation af gasturbiner',\n",
       " ' Da Gazprom efter ti dages vedligehold i sidste uge genåbnede for gasforsyningen til Tyskland, var meldingen, at der dagligt ville blive leveret cirka 67 millioner kubikmeter',\n",
       " 'Gazproms seneste melding betyder altså, at leverancerne til Europa bliver omtrent halveret fra onsdag',\n",
       " ' Gasledningen kan, når den kører for fuld kraft, levere cirka 167 millioner kubikmeter gas om dagen',\n",
       " 'Nordstream 1-faciliter i Lubmin i Tyskland',\n",
       " ' (Foto:\\xa0HANNIBAL HANSCHKE ©\\xa0Ritzau Scanpix)']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = re.split(r'\\.', text) #Remember that \".\" is a special character in regex, so we need to escape it with \"\\\"\n",
    "sentences"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "toc": {
   "nav_menu": {
    "height": "328px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
